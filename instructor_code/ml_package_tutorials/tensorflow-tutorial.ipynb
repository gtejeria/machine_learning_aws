{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TensorFlow](notebook_diagrams/tensorflow.png)\n",
    "\n",
    "# Tutorial for TensorFlow\n",
    "TensorFlow is a library for creating scalable deep learning models that are efficient and compact.  It is widely used across deep learning applications, and is actually used as the backend for Keras.  Compared to **PyTorch** and **Keras**, it is the most computationally-efficient library of these three popular frameworks, and because of this it is quite often used for deploying models.\n",
    "\n",
    "**NOTE**: TensorFlow 2.0 just came\n",
    "\n",
    "The key element behind TensorFlow's efficiency is the [computation graph](https://medium.com/ai%C2%B3-theory-practice-business/tensorflow-1-0-vs-2-0-part-1-computational-graphs-4bb6e31c1a0f).  This is a directed graph where different nodes (circles on the diagram below) represent different TensorFlow operations, and edges (arrows on the diagram below) represent tensors \"flowing\" between operations.\n",
    "\n",
    "![tf-comp-graph](notebook_diagrams/tf_comp_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Block\n",
    "**NOTE**: We'll be using TensorFlow 1.15, CPU-only, for this tutorial, but TensorFlow 2.0 is the most recent version of this package, and therefore contains the most advanced capabilities.\n",
    "\n",
    "TensorFlow is a large Python package, particularly when cuda (which is used when making GPU computations) bindings are installed.  If you know you will only be using a CPU for TensorFlow, it is advisable that you install a CPU-only version of this package.\n",
    "\n",
    "**Known Windows 8 Issue**: If you are running this on Windows 8, please see [this Stack Overflow post](https://stackoverflow.com/questions/46736219/installing-tensorflow-gpu-on-win-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TensorFlow\n",
    "!pip install tensorflow_cpu==1.15\n",
    "\n",
    "# Import TensorFlow\n",
    "import tensorflow as tf  # Don't need to do \"as tf\", but typically just done out of convention\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "# Install/import other image processing libraries\n",
    "! pip install Pillow\n",
    "! pip install --upgrade scipy\n",
    "! pip install --upgrade scikit-learn\n",
    "! pip install imageio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import cv2 as cv\n",
    "\n",
    "# For file paths\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction to the Tensor Data Type\n",
    "In addition to the computation graph, TensorFlow is also able to create efficient code for deep learning using the `tensor` data type, an object they created that optimizes the flow of information through computation graphs.  This object is similar to the numpy `nd_array` object we saw with numpy, and is used to store and transform numerical data through different computation graphs/deep learning pipelines.\n",
    "\n",
    "A TensorFlow `tensor` has two different properties:\n",
    "\n",
    "1. A data type (e.g. `int32`, `float32`)\n",
    "\n",
    "2. A shape (which also determines **Rank**, or the number of dimensions of a `tensor` object).\n",
    "\n",
    "Like numpy `nd_array` objects, TensorFlow `tensor` objects must have the same data type for all elements in the tensor.  There are many kinds of `tf.tensor` objects, but the only **mutable** (changeable) of these objects is `tf.Variable`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank 0 Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create some TensorFlow tensors!\n",
    "mammal = tf.Variable(\"Elephant\", tf.string)\n",
    "ignition = tf.Variable(451, tf.int16)\n",
    "floating = tf.Variable(3.14159265359, tf.float64)\n",
    "its_complicated = tf.Variable(12.3 - 4.85j, tf.complex64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank 1 Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create some TensorFlow tensors!\n",
    "mystr = tf.Variable([\"Hello\"], tf.string)\n",
    "cool_numbers  = tf.Variable([3.14159, 2.71828], tf.float32)\n",
    "first_primes = tf.Variable([2, 3, 5, 7, 11], tf.int32)\n",
    "its_very_complicated = tf.Variable([12.3 - 4.85j, 7.5 - 6.23j], tf.complex64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank 2 Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create some TensorFlow tensors!\n",
    "mymat = tf.Variable([[7],[11]], tf.int16)\n",
    "myxor = tf.Variable([[False, True],[True, False]], tf.bool)\n",
    "linear_squares = tf.Variable([[4], [9], [16], [25]], tf.int32)\n",
    "squarish_squares = tf.Variable([ [4, 9], [16, 25] ], tf.int32)\n",
    "rank_of_squares = tf.rank(squarish_squares)\n",
    "mymatC = tf.Variable([[7],[11]], tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, here is a table showing how different inputs lead to different `tensor` ranks:\n",
    "    \n",
    "![Tensor Rank Table](notebook_diagrams/tensorflow_rank_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Math Operations with TensorFlow Tensors\n",
    "Like numpy `nd_array` objects, we can also use `tf.tensor` objects for doing mathematical operations in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "print(tf.add(1, 2))\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "\n",
    "# Operator overloading is also supported\n",
    "print(tf.square(2) + tf.square(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "x = tf.matmul([[1]], [[2, 3]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Converting Between Numpy and TensorFlow\n",
    "Numpy and TensorFlow are quite compatible with each other, which is extremely useful particularly when we can pre-process our data with numpy and/or OpenCV and then load this pre-processed data into TensorFlow.\n",
    "\n",
    "Calling the method `.numpy()` on a `tf.tensor` object (e.g. `tf.tensor.numpy()`) will convert the data type to a numpy `nd_array` (this could be relevant if we wanted to do post-processing of our data in numpy or openCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "\n",
    "print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n",
    "tensor = tf.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "print(\"And NumPy operations convert Tensors to numpy arrays automatically\")\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Neural Network Models in TensorFlow\n",
    "Neural network models in TensorFlow are similar to what we've seen in Keras (since Keras is built on top of TensorFlow).  We'll explore two aspects of creating your own models with TensorFlow below:\n",
    "\n",
    "1. Creating custom layers\n",
    "\n",
    "2. Creating models using composition of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Creating Custom Layers\n",
    "\n",
    "Material referenced from this [TensorFlow tutorial](https://www.tensorflow.org/tutorials/customization/custom_layers).\n",
    "\n",
    "The best way to implement your own layer is extending the `tf.keras.Layer` class and implementing the constructor method `* __init__` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):  # Notice how we use Keras here!\n",
    "  def __init__(self, num_outputs):\n",
    "    super(MyDenseLayer, self).__init__()\n",
    "    self.num_outputs = num_outputs\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.kernel = self.add_variable(\"kernel\",\n",
    "                                    shape=[int(input_shape[-1]),\n",
    "                                           self.num_outputs])\n",
    "\n",
    "  def call(self, input):\n",
    "    return tf.matmul(input, self.kernel)\n",
    "\n",
    "# Make an instance of this layer\n",
    "layer = MyDenseLayer(10)\n",
    "\n",
    "# Now, make sure we call layer on something to \".build\" it (we can ignore output).\n",
    "_ = layer(tf.zeros([10, 5])) # Calling the layer `.builds` it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Creating Custom Models\n",
    "\n",
    "Material also referenced from [this TensorFlow tutorial](https://www.tensorflow.org/tutorials/customization/custom_layers).\n",
    "\n",
    "We can use the framework outlined in the class definition below to implement our own custom models.  Below, we will look at the mechanics of creating a **ResNet** block (as visualized below).\n",
    "\n",
    "![ResNet identity block](notebook_diagrams/resnet_identity_block.png)\n",
    "\n",
    "**NOTE**: The block of code below is meant only to serve as an example of how we can create different models, and isn't one you have to know specifically.  If you're interested in creating your own custom model, you can use the **general** structure of the code block: the `__init__` and `call` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "  \n",
    "  # This is called the constructor method, and determines what happens when we \"instantiate this object\"\n",
    "  def __init__(self, kernel_size, filters):\n",
    "    super(ResnetIdentityBlock, self).__init__(name='')\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "  # This function defines how an input is mapped into a prediction\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    x += input_tensor\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "# Create an instance of this model\n",
    "block = ResnetIdentityBlock(1, [1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing a Model Summary\n",
    "Since the models we're calling are Keras models, we can again simply call `model.summary()` to view important parameters and characteristics about the models we create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we build the model first - can call it on an arbitrary input of correct input size\n",
    "_ = block(tf.zeros([1, 2, 3, 3])) \n",
    "\n",
    "# Now we can summarize\n",
    "block.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Creating Models in TensorFlow Using Keras\n",
    "If we aren't creating custom models or layers in TensorFlow, it usually makes more sense to just create our models using Keras.  This is identical to what we saw before (with the exception of placing a `tf.` in front of every keras object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model in the exact same way as we did before!\n",
    "my_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1),\n",
    "                                                    input_shape=(\n",
    "                                                        None, None, 3)),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(2, 1,\n",
    "                                                    padding='same'),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(3, (1, 1)),\n",
    "                             tf.keras.layers.BatchNormalization()])\n",
    "\n",
    "# Remember to build the model\n",
    "my_seq(tf.zeros([1, 2, 3, 3]))\n",
    "\n",
    "# Now we can summarize/train the model\n",
    "my_seq.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training in TensorFlow\n",
    "Training, in particular custom training, is another reason to consider using TensorFlow for your next machine learning project.  In this section, we will explore an example of training both a pre-trained **Convolutional Neural Network (CNN)**.  We will walk through each section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Import Statements for ConvNet Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Make easier to read\n",
    "keras = tf.keras\n",
    "\n",
    "# Use for loading datasets\n",
    "!pip install tensorflow_datasets\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Load Dataset using tensorflow_datasets (tfds)\n",
    "We can directly download datasets from tensorflow using the package `tensorflow_datasets`, which we installed above.  We can split our dataset into training, testing, and evaluation, as we did so before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split weights for training/testing/evaluation\n",
    "SPLIT_WEIGHTS = (8, 1, 1)  # Numbers denote (train, validation, test)\n",
    "\n",
    "# Split dataset\n",
    "splits = tfds.Split.TRAIN.subsplit(weighted=SPLIT_WEIGHTS)  # Split according to our weights above\n",
    "\n",
    "# Load cats_vs_dogs dataset\n",
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'cats_vs_dogs', split=list(splits),\n",
    "    with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 View Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print training data\n",
    "print(\"Training data: \\n %s \\n \\n\" % (raw_train))\n",
    "print(\"Type of training data: \\n %s \\n \\n\" % (type(raw_train)))\n",
    "\n",
    "# print validation data\n",
    "print(\"Validation data: \\n %s \\n \\n\" % (raw_validation))\n",
    "print(\"Type of validation data: \\n %s \\n \\n\" % (type(raw_validation)))\n",
    "\n",
    "# print testing data\n",
    "print(\"Test data: \\n %s \\n \\n\" % (raw_test))\n",
    "print(\"Type of validation data: \\n %s \\n \\n\" % (type(raw_validation)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 View Examples from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "# Iteratively show images and labels\n",
    "for image, label in raw_train.take(2):\n",
    "  plt.figure()\n",
    "  plt.imshow(image)\n",
    "  plt.title(get_label_name(label))\n",
    "  plt.show()\n",
    "  plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Preprocess Data to Equal Size, and Scale Pixel Values\n",
    "This is a critical step for developing bug-free and effective datasets for deep learning pipelines.  Here, we will use the `tf.image.resize` function resize the image to the size of `(IMG_SIZE, IMG_SIZE)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 160 # All images will be resized to 160x160\n",
    "\n",
    "def format_example(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image/127.5) - 1\n",
    "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Create Pre-trained ConvNet Model\n",
    "Here is where transfer learning will help us for solving our machine learning problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image size to determine input shape of network\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')  # Notice here that we're using weights from ImageNet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 Create Datasets and Specify Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make datasets\n",
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)\n",
    "\n",
    "# Specify hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "\n",
    "# Make training batches\n",
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8 Run Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image batch from dataset\n",
    "for image_batch, label_batch in train_batches.take(1):\n",
    "   print(\"Inspecting image batch!\")\n",
    "\n",
    "# Inspect an image batch\n",
    "print(\"Image batch shape: %s\" % (image_batch.shape))\n",
    "\n",
    "# Call the model on the image batch\n",
    "feature_batch = base_model(image_batch)\n",
    "print(\"Feature batch shape: %s\" % (feature_batch.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.9 Get Model Summary and Keep Weights Frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the base model architecture\n",
    "print(base_model.summary())\n",
    "\n",
    "# Make sure weights are frozen\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.10 Add Final Layers to Transform Features into Predictions, and Stack Into Aggregate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First do a global averaging\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make a final prediction layer\n",
    "prediction_layer = keras.layers.Dense(1)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, build the overall model\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.11 Compile Model Using Keras and Summarize It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify learning rate\n",
    "base_learning_rate = 0.0001\n",
    "\n",
    "# Compile model using Keras\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summarize aggregated model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.12 Now We Are Ready to Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train, num_val, num_test = (\n",
    "  metadata.splits['train'].num_examples*weight/10\n",
    "  for weight in SPLIT_WEIGHTS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs = 10\n",
    "steps_per_epoch = round(num_train)//BATCH_SIZE\n",
    "validation_steps=20\n",
    "\n",
    "loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit the model by training it\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=initial_epochs,\n",
    "                  \n",
    "                    validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.13 Plot Evaluation Curves To Visualize Our Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Processing Images Using TensorFlow\n",
    "We will provide an example for processing images as input data to TensorFlow.  However, image data is the not the only kind of data TensorFlow can take as input!  TensorFlow is quite useful for taking a variety of other kinds of data, such as time series, audio data, video data, and panel/cross-sectional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5: DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Configuring Devices (CPU and GPU) for TensorFlow\n",
    "TensorFlow has many capabilities for doing computations on both the CPU and GPU.  GPU computations are another feature of TensorFlow that contribute to its effectiveness as a deployable machine learning packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "TensorFlow is a powerful, efficient, and highly-scalable machine learning package for deep learning.  This tutorial covers only a very small fraction of the features and applications of this powerful framework, and we highly encourage you to explore all the capabilities this package offers.  \n",
    "\n",
    "You can find TensorFlow's online tutorials [here](https://www.tensorflow.org/tutorials).  Note that in addition to you being able to download the Jupyter notebooks that TensorFlow provides and run them on your own machine, you can also run TensorFlow's Jupyter notebooks through [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).  \n",
    "\n",
    "We hope this tutorial has provided you with a high-level idea of how TensorFlow works, why it works, and what it can be used for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
