{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Now with Text :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle StumbleUpon Competition\n",
    "\n",
    "https://www.kaggle.com/c/stumbleupon\n",
    "\n",
    "** Competition **: \n",
    "1. Some web pages, such as news articles or seasonal recipes, are only relevant for a short period of time. Others continue to be important for a long time.\n",
    "2. The goal is to identify pages which pages will be relevant for a short span of time, and which will be relevant for a long span on time and are thus considered \"evergreen\". \n",
    "\n",
    "** Evaluation **: Area under the curve (AUC) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Python Modules \n",
    "================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick hack to fix import path\n",
    "# import sys; sys.path.append('/Users/julianalverio/code/conda/envs/sac/lib/python3.6/site-packages/')\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plots\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "\n",
    "# classification algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "# dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# cross-validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "\n",
    "# text features\n",
    "import re\n",
    "from nltk import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.chdir(os.path.join(\"..\", \"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -O /home/ubuntu/machine_learning_aws/data/train.tsv \"https://www.dropbox.com/s/10ch2yhfk8tyfri/train.tsv?dl=0\"\n",
    "data = pd.read_table(\"/home/ubuntu/machine_learning_aws/data/train.tsv\", sep= \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Numerical Features (same as last week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alchemy category, converting to one-hots\n",
    "df = data['alchemy_category']   # 2K ? values\n",
    "one_hots = pd.get_dummies(data['alchemy_category'])\n",
    "df = one_hots\n",
    "rename_dict = {'?': 'alchemy_cat_?'}\n",
    "df = df.rename(columns=rename_dict)\n",
    "\n",
    "# FrameTagRatio, leaving as continuous number\n",
    "df_var = data['frameTagRatio']\n",
    "df['frame_tag_ratio'] = df_var\n",
    "\n",
    "\n",
    "\n",
    "# link word score, 0-100 gaussian, keeping continuous\n",
    "df['link_word_score'] = data['linkwordscore']\n",
    "\n",
    "\n",
    "# alchemy category score, with replacing missing values with random\n",
    "df_var = data['alchemy_category_score']\n",
    "df_var_temp = df_var.apply(lambda x: np.random.random() if x == '?' else float(x)).astype('float32')\n",
    "df['alchemy_category_score'] = df_var_temp\n",
    "\n",
    "\n",
    "# num word in url -- discrete 0-25 to custom binning from looking at the histogram\n",
    "df_var = data['numwords_in_url']\n",
    "bins = [0, 6, 8, 13, 25]\n",
    "df_var_temp = pd.cut(x=df_var, bins=bins, right=True, labels=['num_words_url_bin_0', 'num_words_url_bin_1', 'num_words_url_bin_2', 'num_words_url_bin_3'])\n",
    "dummies = pd.get_dummies(df_var_temp)\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "\n",
    "# parameterized_link_ratio -- leaving as continuous, right-half gaussian\n",
    "df['parameterized_link_ratio'] = data['parametrizedLinkRatio']\n",
    "\n",
    "# spelling errors ratio -- leaving as continuous\n",
    "df['spelling_errors_ratio'] = data['spelling_errors_ratio']\n",
    "\n",
    "# embed_ratio -- bimodal continuous binned into 2 bins\n",
    "df_var = pd.DataFrame(data['embed_ratio'])\n",
    "df_var = df_var['embed_ratio'].apply(lambda x: 1 if x > -1 else 0)\n",
    "dummies = pd.get_dummies(df_var)\n",
    "rename = {0: 'embed_ratio_0', 1: 'embed_ratio_1'}\n",
    "dummies = dummies.rename(columns=rename)\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "\n",
    "# html_ratio -- leaving continuous\n",
    "df['html_ratio'] = data['html_ratio']\n",
    "\n",
    "# lengthy_link_domain\n",
    "df_var = pd.get_dummies(data['lengthyLinkDomain'])\n",
    "rename = {0: 'lengthy_link_domain_0', 1: 'lengthy_link_domain_1'}\n",
    "df_var = df_var.rename(columns=rename)\n",
    "df = pd.concat([df, df_var], axis=1)\n",
    "\n",
    "df['labels'] = data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(df, test_size=0.5, train_size=0.5, random_state=234)\n",
    "val, test = train_test_split(val, test_size=0.5, train_size=0.5, random_state= 675)\n",
    "train_labels = train['labels']\n",
    "train = train.drop(['labels'], axis=1, inplace=False)\n",
    "val_labels = val['labels']\n",
    "val = val.drop(['labels'], axis=1, inplace=False)\n",
    "test_labels = test['labels']\n",
    "test = test.drop(['labels'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Time : logistic regression with numericla features : AUC=0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train, train_labels)\n",
    "preds = model.predict_proba(val)[:,1]\n",
    "score = roc_auc_score(val_labels, preds)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 : Textual feature with Count Vectorizer (Bag of Words)\n",
    "\n",
    "- min_df = minimum freuencey cut-off\n",
    "- max_features = take the top 1000 most common feature\n",
    "- strip_accents = to handle non english letters\n",
    "- ngram_range = we are doing bag of word features here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF add in the text features with tfidf\n",
    "unigram_dtm = CountVectorizer(min_df= 10,  max_features= 1000, strip_accents= \"unicode\",\n",
    "                          ngram_range=(1, 1))\n",
    "unigram_dtm.fit(data[\"boilerplate\"])\n",
    "data_text = unigram_dtm.transform(data[\"boilerplate\"])\n",
    "train_text, val_text = train_test_split(data_text, test_size=0.5, train_size=0.5, random_state=234)\n",
    "val_text, test_text = train_test_split(val_text, test_size=0.5, train_size=0.5, random_state= 675)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(unigram_dtm.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = train_text.toarray()\n",
    "print (xx.shape)\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_text = pd.concat([train.reset_index(drop = True), pd.DataFrame(train_text.toarray())], axis=1)\n",
    "val_with_text = pd.concat([val.reset_index(drop = True), pd.DataFrame(val_text.toarray())], axis=1)\n",
    "train_with_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_with_text, train_labels)\n",
    "preds = model.predict_proba(val_with_text)[:,1]\n",
    "score = roc_auc_score(val_labels, preds)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Textual Features with Count Vectorizer (Bi-Gram)\n",
    "- ngram_range = (2,2) now so we only bi-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF add in the text features with tfidf\n",
    "bigram_dtm = CountVectorizer(min_df= 10,  max_features= 1000, strip_accents= \"unicode\",\n",
    "                          ngram_range=(2, 2))\n",
    "bigram_dtm.fit(data[\"boilerplate\"])\n",
    "data_text = bigram_dtm.transform(data[\"boilerplate\"])\n",
    "train_text, val_text = train_test_split(data_text, test_size=0.5, train_size=0.5, random_state=234)\n",
    "val_text, test_text = train_test_split(val_text, test_size=0.5, train_size=0.5, random_state= 675)\n",
    "\n",
    "train_with_text = pd.concat([train.reset_index(drop = True), pd.DataFrame(train_text.toarray())], axis=1)\n",
    "val_with_text = pd.concat([val.reset_index(drop = True), pd.DataFrame(val_text.toarray())], axis=1)\n",
    "train_with_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(bigram_dtm.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_with_text, train_labels)\n",
    "preds = model.predict_proba(val_with_text)[:,1]\n",
    "score = roc_auc_score(val_labels, preds)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Textual Features with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF add in the text features with tfidf\n",
    "idf_dtm = TfidfVectorizer(min_df= 10,  max_features= 1000, strip_accents= \"unicode\", ngram_range=(1, 2))\n",
    "idf_dtm.fit(data[\"boilerplate\"])\n",
    "data_text = idf_dtm.transform(data[\"boilerplate\"])\n",
    "train_text, val_text = train_test_split(data_text, test_size=0.5, train_size=0.5, random_state=234)\n",
    "val_text, test_text = train_test_split(val_text, test_size=0.5, train_size=0.5, random_state= 675)\n",
    "\n",
    "train_with_text = pd.concat([train.reset_index(drop = True), pd.DataFrame(train_text.toarray())], axis=1)\n",
    "val_with_text = pd.concat([val.reset_index(drop = True), pd.DataFrame(val_text.toarray())], axis=1)\n",
    "train_with_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(idf_dtm.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_with_text, train_labels)\n",
    "preds = model.predict_proba(val_with_text)[:,1]\n",
    "score = roc_auc_score(val_labels, preds)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
