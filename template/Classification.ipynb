{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: End-to-end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle StumbleUpon Competition\n",
    "\n",
    "https://www.kaggle.com/c/stumbleupon\n",
    "\n",
    "** Competition **: \n",
    "1. Some web pages, such as news articles or seasonal recipes, are only relevant for a short period of time. Others continue to be important for a long time.\n",
    "2. The goal is to identify pages which pages will be relevant for a short span of time, and which will be relevant for a long span on time and are thus considered \"evergreen\". \n",
    "\n",
    "** Evaluation **: Area under the curve (AUC) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Python Modules \n",
    "================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick hack to fix import path\n",
    "# import sys; sys.path.append('/Users/julianalverio/code/conda/envs/sac/lib/python3.6/site-packages/')\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plots\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "\n",
    "# classification algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "# dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# cross-validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.chdir(os.path.join(\"..\", \"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table(\"stumbleupon/train.tsv\", sep= \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable descriptions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **url**: Url of the webpage to be classified\n",
    "2. **urlid**: StumbleUpon's unique identifier for each url\n",
    "3. **boilerplate**: Boilerplate text\n",
    "4. **alchemy_category**:\tAlchemy category\n",
    "5. **alchemy_category_score**:\tAlchemy category score\n",
    "6. **avglinksize**:\tAverage number of words in each link\n",
    "7. **commonLinkRatio_1**:\t# of links sharing at least 1 word with 1 other links / # of links\n",
    "8. **commonLinkRatio_2**:\t# of links sharing at least 1 word with 2 other links / # of links\n",
    "9. **commonLinkRatio_3**:\t# of links sharing at least 1 word with 3 other links / # of links\n",
    "10. **commonLinkRatio_4**:\t# of links sharing at least 1 word with 4 other links / # of links\n",
    "11. **compression_ratio**:\tCompression achieved on this page via gzip (measure of redundancy)\n",
    "12. **embed_ratio**: Count of number of \"embed\" usage\n",
    "13. **frameBased**: A page is frame-based (1) if it has no body markup but have a frameset markup\n",
    "14. **frameTagRatio**: Ratio of iframe markups over total number of markups\n",
    "15. **hasDomainLink**:\tTrue (1) if it contains an \"a\" with an url with domain\n",
    "16. **html_ratio**:\tRatio of tags vs text in the page\n",
    "17. **image_ratio**: Ratio of \"img\" tags vs text in the page\n",
    "18. **is_news**: True (1) if StumbleUpon's news classifier determines that this webpage is news\n",
    "19. **lengthyLinkDomain**: True (1) if at least 3 \"a\"'s text contains more than 30 alphanumeric characters\n",
    "20. **linkwordscore**: Percentage of words on the page that are in hyperlink's text\n",
    "21. **news_front_page**: True (1) if StumbleUpon's news classifier determines that this webpage is front-page news\n",
    "22. **non_markup_alphanum_characters**:\tinteger\tPage's text's number of alphanumeric characters\n",
    "23. **numberOfLinks**: Number of \"a\"  markups\n",
    "24. **numwords_in_url**: Number of words in url\n",
    "25. **parametrizedLinkRatio**: A link is parametrized if it's url contains parameters  or has an attached onClick event\n",
    "26. **spelling_errors_ratio**: Ratio of words not found in wiki (considered to be a spelling mistake)\n",
    "27. **label**: User-determined label. Either evergreen (1) or non-evergreen (0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "No Good\n",
    "url -- object type, the literal url\n",
    "urlid -- uid for the url, drop it\n",
    "avglinksize -- huge spread, mostly around 1 or two. This would need to be hella binned carefully. I think useless from Madhav's results\n",
    "frameBased -- 0 everywhere, garbage\n",
    "is_news -- 1 everywhere\n",
    "\n",
    "TEXT\n",
    "boilerplate -- text feature\n",
    "\n",
    "NUMERICAL\n",
    "alchemy_category -- business, health, sports, etc.\n",
    "alchemy_category_score -- 0 to 1 STRING with LOTS of '?' values\n",
    "commonlinkratio -- cont value from 0 to 1 that works nicely, needs binning. Nice gaussian on 1, moves to left with increasing idx\n",
    "compression_ratio -- continuous value with huge bimodal spread -- needs to be binned carefully\n",
    "embed_ratio -- perfect bimodal spread -- two humps. -1 and 0.25\n",
    "frameTagRatio -- 0 to 0.44 cont, spread leans left -- it is half a gaussian\n",
    "hasDomainLink -- 0/1 categorical, almost all 0\n",
    "html_ratio -- cont 0 to 0.7, gaussian spread\n",
    "image_ratio -- spread -1 to 113, but almost exclusively right at 0\n",
    "lengthy-link domain -- categorical 0/1, good spread\n",
    "linkwordscore -- 0 to 100 good spread\n",
    "news_front_page -- STRING, ? values, 0-1 categorical, almost all 0\n",
    "non_markup_alphnum_characters -- huge spread, highly concentrated near 0\n",
    "numberoflinks -- huge spread, mostly close to 0\n",
    "numwordsinurl -- good spread, 0 to 25, has a long upper tail\n",
    "Parametrizedlinkratio -- 0 to 1 continuous, skewed toward 0 -- right half of gaussian\n",
    "spelling_errors_ratio -- 0 to 1, heavy leaning to 0\n",
    "\n",
    "\n",
    "Entropy measures on each feature\n",
    "\n",
    "[(-0.0017029098026004608, 'avglinksize'),\n",
    " (-0.0015477640384510272, 'image_ratio'),\n",
    " (-0.0013366491854696072, 'numberOfLinks'),\n",
    " (-0.0012422148274934264, 'urlid'),\n",
    " (-0.0012276386004722584, 'non_markup_alphanum_characters'),\n",
    " (-0.0003632131231506852, 'hasDomainLink'),\n",
    " (-1.6445368175466157e-05, 'compression_ratio'),\n",
    " (0, 'alchemy_category_score'),\n",
    " (0, 'boilerplate'),\n",
    " (0, 'commonLinkRatio_1'),\n",
    " (0, 'commonLinkRatio_2'),\n",
    " (0, 'commonLinkRatio_3'),\n",
    " (0, 'commonLinkRatio_4'),\n",
    " (0, 'frameBased'),\n",
    " (0, 'is_news'),\n",
    " (0, 'label'),\n",
    " (0, 'news_front_page'),\n",
    " (0, 'url'),\n",
    " (0.00016331922818457745, 'lengthyLinkDomain'),\n",
    " (0.0007063846400122697, 'html_ratio'),\n",
    " (0.0011190978216005787, 'embed_ratio'),\n",
    " (0.0020862547468744053, 'spelling_errors_ratio'),\n",
    " (0.002983052198938685, 'parametrizedLinkRatio'),\n",
    " (0.004883582510772921, 'numwords_in_url'),\n",
    " (0.016376170421172676, 'linkwordscore'),\n",
    " (0.016942353001673127, 'frameTagRatio'),\n",
    " (0.040352206434091764, 'alchemy_category')]\n",
    "\n",
    "'''\n",
    "\n",
    "# Alchemy category, converting to one-hots\n",
    "df = data['alchemy_category']   # 2K ? values\n",
    "one_hots = pd.get_dummies(data['alchemy_category'])\n",
    "df = one_hots\n",
    "rename_dict = {'?': 'alchemy_cat_?'}\n",
    "df = df.rename(columns=rename_dict)\n",
    "\n",
    "# FrameTagRatio, leaving as continuous number\n",
    "df_var = data['frameTagRatio']\n",
    "df['frame_tag_ratio'] = df_var\n",
    "\n",
    "\n",
    "\n",
    "# link word score, 0-100 gaussian, keeping continuous\n",
    "df['link_word_score'] = data['linkwordscore']\n",
    "\n",
    "\n",
    "# alchemy category score, with replacing missing values with random\n",
    "df_var = data['alchemy_category_score']\n",
    "df_var_temp = df_var.apply(lambda x: np.random.random() if x == '?' else float(x)).astype('float32')\n",
    "df['alchemy_category_score'] = df_var_temp\n",
    "\n",
    "\n",
    "# num word in url -- discrete 0-25 to custom binning from looking at the histogram\n",
    "df_var = data['numwords_in_url']\n",
    "bins = [0, 6, 8, 13, 25]\n",
    "df_var_temp = pd.cut(x=df_var, bins=bins, right=True, labels=['num_words_url_bin_0', 'num_words_url_bin_1', 'num_words_url_bin_2', 'num_words_url_bin_3'])\n",
    "dummies = pd.get_dummies(df_var_temp)\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "\n",
    "# parameterized_link_ratio -- leaving as continuous, right-half gaussian\n",
    "df['parameterized_link_ratio'] = data['parametrizedLinkRatio']\n",
    "\n",
    "# spelling errors ratio -- leaving as continuous\n",
    "df['spelling_errors_ratio'] = data['spelling_errors_ratio']\n",
    "\n",
    "# embed_ratio -- bimodal continuous binned into 2 bins\n",
    "df_var = pd.DataFrame(data['embed_ratio'])\n",
    "df_var = df_var['embed_ratio'].apply(lambda x: 1 if x > -1 else 0)\n",
    "dummies = pd.get_dummies(df_var)\n",
    "rename = {0: 'embed_ratio_0', 1: 'embed_ratio_1'}\n",
    "dummies = dummies.rename(columns=rename)\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "\n",
    "# html_ratio -- leaving continuous\n",
    "df['html_ratio'] = data['html_ratio']\n",
    "\n",
    "# lengthy_link_domain\n",
    "df_var = pd.get_dummies(data['lengthyLinkDomain'])\n",
    "rename = {0: 'lengthy_link_domain_0', 1: 'lengthy_link_domain_1'}\n",
    "df_var = df_var.rename(columns=rename)\n",
    "df = pd.concat([df, df_var], axis=1)\n",
    "\n",
    "df['labels'] = data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(df, test_size=0.5, train_size=0.5, random_state=234)\n",
    "val, test = train_test_split(val, test_size=0.5, train_size=0.5, random_state= 675)\n",
    "train_labels = train['labels']\n",
    "train = train.drop(['labels'], axis=1, inplace=False)\n",
    "val_labels = val['labels']\n",
    "val = val.drop(['labels'], axis=1, inplace=False)\n",
    "test_labels = test['labels']\n",
    "test = test.drop(['labels'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_search(budget):\n",
    "    ret = []\n",
    "    for i in range(budget):\n",
    "        seed = random.randrange(500)\n",
    "        rand_C =    random.choice([0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000])\n",
    "        rand_fit_intercept = random.choice([True, False])\n",
    "        rand_penalty = random.choice(['l1', 'l2'])\n",
    "        model = LogisticRegression(random_state=seed, C = rand_C, fit_intercept = rand_fit_intercept, penalty=rand_penalty)\n",
    "        model.fit(train, train_labels)\n",
    "        preds = model.predict_proba(val)[:,1]\n",
    "        score = roc_auc_score(val_labels, preds)\n",
    "        ret.append((score, model))\n",
    "    return list(reversed(sorted(ret, key=lambda x: x[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best logistic regression: AUC=0.71\n",
    "seed = 61\n",
    "C = 1\n",
    "fit_intercept = False\n",
    "penalty = 'l1'\n",
    "model = LogisticRegression(random_state=seed, C=C, fit_intercept=fit_intercept, penalty=penalty)\n",
    "model.fit(train, train_labels)\n",
    "preds = model.predict_proba(val)[:,1]\n",
    "score = roc_auc_score(val_labels, preds)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_search(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbdt_search(budget):\n",
    "    ret = []\n",
    "    for i in range(budget):\n",
    "        # choose a set of random hyper-parameters\n",
    "        seed = random.randrange(500)\n",
    "        ccp_alpha = random.choice([0.0, 0.1])\n",
    "        learning_rate = random.choice([0.001, 0.01, 0.1])\n",
    "        n_estimators = random.choice([10, 30, 80, 160, 300])\n",
    "        max_depth = random.choice([1,3,5,10])\n",
    "        model = GradientBoostingClassifier(random_state=seed, learning_rate=learning_rate, n_estimators=n_estimators, max_depth = max_depth)\n",
    "        model.fit(train, train_labels)\n",
    "        preds = model.predict_proba(val)[:,1]\n",
    "        score = roc_auc_score(val_labels, preds)\n",
    "        ret.append((score, model))\n",
    "    return list(reversed(sorted(ret, key=lambda x: x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Gradient Boosted Decision Tree: AUC=0.73\n",
    "learning_rate = 0.01\n",
    "max_depth = 3\n",
    "n_estimators = 300\n",
    "random_state = 239\n",
    "model = GradientBoostingClassifier(random_state=seed, learning_rate=learning_rate, n_estimators=n_estimators, max_depth = max_depth)\n",
    "model.fit(train, train_labels)\n",
    "preds = model.predict_proba(val)[:,1]\n",
    "score = roc_auc_score(val_labels, preds)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbdt_search(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_search(budget):\n",
    "    ret = []\n",
    "    for i in range(budget):\n",
    "        # choose a set of random hyper-parameters\n",
    "        seed = random.randrange(500)\n",
    "        C = random.choice([0.0001, 0.001, 0.01, 0.1, 1.0])\n",
    "        kernel = random.choice(['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "        print (\"running for \", C, kernel)\n",
    "        model = svm.SVC(random_state=seed, C=C, kernel=kernel, probability=True)\n",
    "        model.fit(train, train_labels)\n",
    "        preds = model.predict_proba(val)[:,1]\n",
    "        score = roc_auc_score(val_labels, preds)\n",
    "        ret.append((score, model))\n",
    "        print (score, model)\n",
    "    return list(reversed(sorted(ret, key=lambda x: x[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_search(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best SVM: AUC=0.7\n",
    "C = 0.1\n",
    "kernel = 'linear'\n",
    "seed = 184\n",
    "model = svm.SVC(random_state=seed, C=C, kernel=kernel, probability=True)\n",
    "model.fit(train, train_labels)\n",
    "preds = model.predict_proba(val)[:,1]\n",
    "score = roc_auc_score(val_labels, preds)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Note **: Scikit-learn training algorithms do not accept categorical features and hence they need to be converted to numeric or binary before fitting the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did really well for only using numerical features, but there's much more to be done! Dimensionality reduction, text processing, and more. Stay tuned for next week's natural language processing (NLP) theme.\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
